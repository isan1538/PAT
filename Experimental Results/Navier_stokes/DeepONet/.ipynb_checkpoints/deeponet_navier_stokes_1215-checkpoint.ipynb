{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067fc94d-0931-4c18-ac95-6f677995884f",
   "metadata": {},
   "source": [
    "DeepONet for Navier-Stokes\n",
    "===========================\n",
    "\n",
    "Deep Operator Network with branch and trunk networks.\n",
    "Branch: learns from function values at sensor locations\n",
    "Trunk: learns coordinate encoding\n",
    "\n",
    "python deeponet_navier_stokes.py --data_path ./cylinder_nektar_wake.mat \\\n",
    "  --device cuda --seed 0 --test_t_idx 100 --n_sensors 100 \\\n",
    "  --n_query 1000 --hidden_dim 128 --depth 4 --p 100 --steps 1000 \\\n",
    "  --batch_size 32 --lr 1e-3 --save_path checkpoints/deeponet_ns.pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928bcd6f-890f-4ddc-9b74-4f2378ab6c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a27df-cd93-4182-a61c-5f3b2bc502f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "class DeepONet(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim=3, hidden_dim=128, \n",
    "                 depth=4, p=100, out_dim=3):\n",
    "        \"\"\"\n",
    "        branch_input_dim: number of sensors * channels\n",
    "        trunk_input_dim: coordinate dimension (x, y, t)\n",
    "        p: dimension of the inner product space\n",
    "        out_dim: number of output fields (u, v, p)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        # Branch network (processes sensor data)\n",
    "        branch_layers = []\n",
    "        branch_layers.append(nn.Linear(branch_input_dim, hidden_dim))\n",
    "        branch_layers.append(nn.Tanh())\n",
    "        for _ in range(depth - 1):\n",
    "            branch_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            branch_layers.append(nn.Tanh())\n",
    "        branch_layers.append(nn.Linear(hidden_dim, p * out_dim))\n",
    "        self.branch = nn.Sequential(*branch_layers)\n",
    "        \n",
    "        # Trunk network (processes coordinates)\n",
    "        trunk_layers = []\n",
    "        trunk_layers.append(nn.Linear(trunk_input_dim, hidden_dim))\n",
    "        trunk_layers.append(nn.Tanh())\n",
    "        for _ in range(depth - 1):\n",
    "            trunk_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            trunk_layers.append(nn.Tanh())\n",
    "        trunk_layers.append(nn.Linear(hidden_dim, p * out_dim))\n",
    "        self.trunk = nn.Sequential(*trunk_layers)\n",
    "        \n",
    "        # Bias\n",
    "        self.bias = nn.Parameter(torch.zeros(out_dim))\n",
    "    \n",
    "    def forward(self, u_sensors, coords):\n",
    "        \"\"\"\n",
    "        u_sensors: (B, n_sensors * channels) - values at sensor locations\n",
    "        coords: (B, N, 3) - query coordinates (x, y, t)\n",
    "        Returns: (B, N, out_dim) - predicted fields\n",
    "        \"\"\"\n",
    "        B, N, _ = coords.shape\n",
    "        \n",
    "        # Branch network\n",
    "        branch_out = self.branch(u_sensors)  # (B, p * out_dim)\n",
    "        branch_out = branch_out.view(B, self.out_dim, self.p)  # (B, out_dim, p)\n",
    "        \n",
    "        # Trunk network\n",
    "        coords_flat = coords.reshape(B * N, -1)\n",
    "        trunk_out = self.trunk(coords_flat)  # (B*N, p * out_dim)\n",
    "        trunk_out = trunk_out.view(B, N, self.out_dim, self.p)  # (B, N, out_dim, p)\n",
    "        \n",
    "        # Inner product\n",
    "        out = torch.einsum('bop,bnop->bno', branch_out, trunk_out)\n",
    "        out = out + self.bias.view(1, 1, -1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class CylinderWakeData:\n",
    "    def __init__(self, mat_path, n_sensors=100, seed=0):\n",
    "        data = scipy.io.loadmat(mat_path)\n",
    "        self.U_star = data[\"U_star\"]\n",
    "        self.p_star = data[\"p_star\"]\n",
    "        self.X_star = data[\"X_star\"]\n",
    "        self.t_star = data[\"t\"]\n",
    "        \n",
    "        self.N = self.X_star.shape[0]\n",
    "        self.T = self.t_star.shape[0]\n",
    "        self.n_sensors = n_sensors\n",
    "        \n",
    "        # Flatten\n",
    "        XX = np.tile(self.X_star[:, 0:1], (1, self.T))\n",
    "        YY = np.tile(self.X_star[:, 1:2], (1, self.T))\n",
    "        TT = np.tile(self.t_star, (1, self.N)).T\n",
    "        \n",
    "        self.x = XX.flatten()[:, None]\n",
    "        self.y = YY.flatten()[:, None]\n",
    "        self.t = TT.flatten()[:, None]\n",
    "        self.u = self.U_star[:, 0, :].flatten()[:, None]\n",
    "        self.v = self.U_star[:, 1, :].flatten()[:, None]\n",
    "        self.p = self.p_star.flatten()[:, None]\n",
    "        \n",
    "        self.NT = self.x.shape[0]\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        \n",
    "        # Fixed sensor locations (randomly selected spatial points)\n",
    "        self.sensor_idx = self.rng.choice(self.N, n_sensors, replace=False)\n",
    "    \n",
    "    def get_training_batch(self, batch_size, n_query_per_func):\n",
    "        \"\"\"\n",
    "        Get training batch:\n",
    "        - Sample batch_size functions (time snapshots)\n",
    "        - For each function, get sensor values and n_query_per_func query points\n",
    "        \"\"\"\n",
    "        # Sample time indices\n",
    "        t_indices = self.rng.choice(self.T, batch_size, replace=True)\n",
    "        \n",
    "        sensor_vals = []\n",
    "        query_coords = []\n",
    "        query_vals = []\n",
    "        \n",
    "        for t_idx in t_indices:\n",
    "            # Sensor values at this time\n",
    "            u_sensor = self.U_star[self.sensor_idx, 0, t_idx]\n",
    "            v_sensor = self.U_star[self.sensor_idx, 1, t_idx]\n",
    "            p_sensor = self.p_star[self.sensor_idx, t_idx]\n",
    "            sensors = np.concatenate([u_sensor, v_sensor, p_sensor])\n",
    "            sensor_vals.append(sensors)\n",
    "            \n",
    "            # Query points (random spatial locations at this time)\n",
    "            query_idx = self.rng.choice(self.N, n_query_per_func, replace=False)\n",
    "            x_q = self.X_star[query_idx, 0:1]\n",
    "            y_q = self.X_star[query_idx, 1:2]\n",
    "            t_q = np.full_like(x_q, self.t_star[t_idx, 0])\n",
    "            coords = np.concatenate([x_q, y_q, t_q], axis=1)\n",
    "            query_coords.append(coords)\n",
    "            \n",
    "            u_q = self.U_star[query_idx, 0, t_idx:t_idx+1]\n",
    "            v_q = self.U_star[query_idx, 1, t_idx:t_idx+1]\n",
    "            p_q = self.p_star[query_idx, t_idx:t_idx+1]\n",
    "            vals = np.concatenate([u_q, v_q, p_q], axis=1)\n",
    "            query_vals.append(vals)\n",
    "        \n",
    "        return (np.array(sensor_vals), \n",
    "                np.array(query_coords),\n",
    "                np.array(query_vals))\n",
    "    \n",
    "    def get_snapshot(self, t_idx):\n",
    "        \"\"\"Get full snapshot for evaluation\"\"\"\n",
    "        # Sensor values\n",
    "        u_sensor = self.U_star[self.sensor_idx, 0, t_idx]\n",
    "        v_sensor = self.U_star[self.sensor_idx, 1, t_idx]\n",
    "        p_sensor = self.p_star[self.sensor_idx, t_idx]\n",
    "        sensors = np.concatenate([u_sensor, v_sensor, p_sensor])\n",
    "        \n",
    "        # All spatial points at this time\n",
    "        x = self.X_star[:, 0:1]\n",
    "        y = self.X_star[:, 1:2]\n",
    "        t = np.full_like(x, self.t_star[t_idx, 0])\n",
    "        coords = np.concatenate([x, y, t], axis=1)\n",
    "        \n",
    "        u = self.U_star[:, 0, t_idx:t_idx+1]\n",
    "        v = self.U_star[:, 1, t_idx:t_idx+1]\n",
    "        p = self.p_star[:, t_idx:t_idx+1]\n",
    "        vals = np.concatenate([u, v, p], axis=1)\n",
    "        \n",
    "        return sensors, coords, vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8df46-009c-401b-acc0-6b7f17db36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(res, history, args, save_dir):\n",
    "    \"\"\"Create comprehensive result plots for DeepONet\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Training curves\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.semilogy(history[\"step\"], history[\"train_loss\"])\n",
    "    ax.set_title(\"Training Loss\")\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.semilogy(history[\"step\"], history[\"test_mse\"])\n",
    "    ax.set_title(\"Test MSE\")\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Prediction visualization\n",
    "    x = res[\"x\"]\n",
    "    y = res[\"y\"]\n",
    "    uvp_true = res[\"uvp_true\"]\n",
    "    uvp_pred = res[\"uvp_pred\"]\n",
    "    \n",
    "    # Detect grid structure\n",
    "    xu = np.unique(np.round(x, 10))\n",
    "    yu = np.unique(np.round(y, 10))\n",
    "    nx, ny = len(xu), len(yu)\n",
    "    \n",
    "    try:\n",
    "        x_to_i = {val: i for i, val in enumerate(xu)}\n",
    "        y_to_j = {val: j for j, val in enumerate(yu)}\n",
    "        \n",
    "        def to_grid(values):\n",
    "            grid = np.full((ny, nx), np.nan)\n",
    "            for xi, yi, val in zip(np.round(x, 10), np.round(y, 10), values):\n",
    "                grid[y_to_j[yi], x_to_i[xi]] = val\n",
    "            return grid\n",
    "        \n",
    "        is_grid = True\n",
    "    except:\n",
    "        is_grid = False\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(14, 10))\n",
    "    \n",
    "    for i, var in enumerate(['u', 'v', 'p']):\n",
    "        true_val = uvp_true[:, i]\n",
    "        pred_val = uvp_pred[:, i]\n",
    "        err_val = np.abs(pred_val - true_val)\n",
    "        \n",
    "        if is_grid:\n",
    "            true_grid = to_grid(true_val)\n",
    "            pred_grid = to_grid(pred_val)\n",
    "            err_grid = to_grid(err_val)\n",
    "            extent = [xu.min(), xu.max(), yu.min(), yu.max()]\n",
    "            \n",
    "            ax = axes[i, 0]\n",
    "            im = ax.imshow(true_grid, origin='lower', aspect='auto', \n",
    "                          extent=extent, cmap='viridis', interpolation='bilinear')\n",
    "            ax.set_title(f'{var} (True)')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            ax = axes[i, 1]\n",
    "            im = ax.imshow(pred_grid, origin='lower', aspect='auto',\n",
    "                          extent=extent, cmap='viridis', interpolation='bilinear')\n",
    "            ax.set_title(f'{var} (Pred)')\n",
    "            ax.set_xlabel('x')\n",
    "            plt.colorbar(im, ax=ax)\n",
    "            \n",
    "            ax = axes[i, 2]\n",
    "            im = ax.imshow(err_grid, origin='lower', aspect='auto',\n",
    "                          extent=extent, cmap='hot', interpolation='bilinear')\n",
    "            ax.set_title(f'{var} (Abs Error)')\n",
    "            ax.set_xlabel('x')\n",
    "            plt.colorbar(im, ax=ax)\n",
    "        else:\n",
    "            ax = axes[i, 0]\n",
    "            sc = ax.scatter(x, y, c=true_val, s=3, cmap='viridis')\n",
    "            ax.set_title(f'{var} (True)')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "            plt.colorbar(sc, ax=ax)\n",
    "            \n",
    "            ax = axes[i, 1]\n",
    "            sc = ax.scatter(x, y, c=pred_val, s=3, cmap='viridis')\n",
    "            ax.set_title(f'{var} (Pred)')\n",
    "            ax.set_xlabel('x')\n",
    "            plt.colorbar(sc, ax=ax)\n",
    "            \n",
    "            ax = axes[i, 2]\n",
    "            sc = ax.scatter(x, y, c=err_val, s=3, cmap='hot')\n",
    "            ax.set_title(f'{var} (Abs Error)')\n",
    "            ax.set_xlabel('x')\n",
    "            plt.colorbar(sc, ax=ax)\n",
    "    \n",
    "    plt.suptitle(f\"DeepONet | MSE={res['mse']:.3e} | t_index={args.test_t_idx}\", y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'predictions.png'), dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Saved plots to {save_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d30185-ebea-433d-ac4e-434c25390585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deeponet(args):\n",
    "    device = torch.device(args.device)\n",
    "    set_seed(args.seed)\n",
    "    \n",
    "    data = CylinderWakeData(args.data_path, n_sensors=args.n_sensors, seed=args.seed)\n",
    "    \n",
    "    # Model\n",
    "    branch_input_dim = args.n_sensors * 3  # 3 channels: u, v, p\n",
    "    model = DeepONet(branch_input_dim=branch_input_dim,\n",
    "                     trunk_input_dim=3,\n",
    "                     hidden_dim=args.hidden_dim,\n",
    "                     depth=args.depth,\n",
    "                     p=args.p,\n",
    "                     out_dim=3).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr,\n",
    "                                 weight_decay=args.weight_decay)\n",
    "    \n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nDeepONet Training\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Parameters: {n_params:,}\")\n",
    "    print(f\"Sensors: {args.n_sensors}\")\n",
    "    print(f\"Inner product dim (p): {args.p}\")\n",
    "    print(f\"Test snapshot: t_idx={args.test_t_idx}\")\n",
    "    \n",
    "    # Get test data\n",
    "    test_sensors, test_coords, test_vals = data.get_snapshot(args.test_t_idx)\n",
    "    test_sensors = torch.tensor(test_sensors, dtype=torch.float32, \n",
    "                               device=device).unsqueeze(0)\n",
    "    test_coords = torch.tensor(test_coords, dtype=torch.float32, \n",
    "                              device=device).unsqueeze(0)\n",
    "    test_vals = torch.tensor(test_vals, dtype=torch.float32, device=device)\n",
    "    \n",
    "    history = {\"step\": [], \"train_loss\": [], \"test_mse\": []}\n",
    "    best_test = float('inf')\n",
    "    \n",
    "    for step in range(1, args.steps + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get training batch\n",
    "        sensors, coords, vals = data.get_training_batch(args.batch_size, \n",
    "                                                        args.n_query)\n",
    "        sensors = torch.tensor(sensors, dtype=torch.float32, device=device)\n",
    "        coords = torch.tensor(coords, dtype=torch.float32, device=device)\n",
    "        vals = torch.tensor(vals, dtype=torch.float32, device=device)\n",
    "        \n",
    "        # Forward\n",
    "        pred = model(sensors, coords)\n",
    "        loss = F.mse_loss(pred, vals)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % args.print_every == 0 or step == 1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred_test = model(test_sensors, test_coords).squeeze(0)\n",
    "                test_mse = F.mse_loss(pred_test, test_vals).item()\n",
    "            \n",
    "            print(f\"[{step:06d}] train_loss={loss.item():.3e} | \"\n",
    "                  f\"test_mse={test_mse:.3e}\")\n",
    "            \n",
    "            history[\"step\"].append(step)\n",
    "            history[\"train_loss\"].append(loss.item())\n",
    "            history[\"test_mse\"].append(test_mse)\n",
    "            \n",
    "            if test_mse < best_test:\n",
    "                best_test = test_mse\n",
    "                if args.save_path:\n",
    "                    os.makedirs(os.path.dirname(args.save_path), exist_ok=True)\n",
    "                    torch.save({\n",
    "                        'model': model.state_dict(),\n",
    "                        'step': step,\n",
    "                        'test_mse': best_test,\n",
    "                        'history': history,\n",
    "                    }, args.save_path)\n",
    "    \n",
    "    print(f\"\\nBest test MSE: {best_test:.3e}\")\n",
    "    \n",
    "    # Final evaluation and plotting\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_test = model(test_sensors, test_coords).squeeze(0)\n",
    "    \n",
    "    res = {\n",
    "        'x': test_coords.squeeze(0)[:, 0].cpu().numpy(),\n",
    "        'y': test_coords.squeeze(0)[:, 1].cpu().numpy(),\n",
    "        'uvp_true': test_vals.cpu().numpy(),\n",
    "        'uvp_pred': pred_test.cpu().numpy(),\n",
    "        'mse': best_test\n",
    "    }\n",
    "    \n",
    "    save_dir = os.path.join(os.path.dirname(args.save_path), 'deeponet_plots')\n",
    "    plot_results(res, history, args, save_dir)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21e835-f330-4338-9c90-bcf278d7e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_path = \"./cylinder_nektar_wake.mat\"\n",
    "    device = \"cuda\"\n",
    "    seed = 0\n",
    "    n_sensors = 100\n",
    "    n_query = 1000\n",
    "    test_t_idx = 100\n",
    "    hidden_dim = 128\n",
    "    depth = 4\n",
    "    p = 100\n",
    "    steps = 5000\n",
    "    batch_size = 32\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    print_every = 100\n",
    "    save_path = \"checkpoints/deeponet_ns.pt\"\n",
    "    \n",
    "args = Config()\n",
    "\n",
    "\n",
    "\n",
    "train_deeponet(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
