{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482278b5-318e-4217-82c1-6b2426881fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_path DATA_PATH] [--t_index T_INDEX]\n",
      "                             [--n_sensors N_SENSORS] [--hidden_dim HIDDEN_DIM]\n",
      "                             [--depth DEPTH] [--p P] [--device DEVICE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\Zigorat\\AppData\\Roaming\\jupyter\\runtime\\kernel-v37536c454a9b54b4430b056fd9133ea04eff77ffc.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load and evaluate trained DeepONet model for Navier-Stokes\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate DeepONet model\n",
    "python evaluate_deeponet.py --checkpoint checkpoints/deeponet_ns.pt\n",
    "\n",
    "# With custom parameters\n",
    "python evaluate_deeponet.py \\\n",
    "    --checkpoint checkpoints/deeponet_ns.pt \\\n",
    "    --data_path ./cylinder_nektar_wake.mat \\\n",
    "    --t_index 100 \\\n",
    "    --n_sensors 100 \\\n",
    "    --hidden_dim 128 \\\n",
    "    --depth 4 \\\n",
    "    --p 100 \\\n",
    "    --device cuda\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Model Definition (same as training script)\n",
    "# =============================================================================\n",
    "\n",
    "class DeepONet(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim=3, hidden_dim=128, \n",
    "                 depth=4, p=100, out_dim=3):\n",
    "        \"\"\"\n",
    "        branch_input_dim: number of sensors * channels\n",
    "        trunk_input_dim: coordinate dimension (x, y, t)\n",
    "        p: dimension of the inner product space\n",
    "        out_dim: number of output fields (u, v, p)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        # Branch network (processes sensor data)\n",
    "        branch_layers = []\n",
    "        branch_layers.append(nn.Linear(branch_input_dim, hidden_dim))\n",
    "        branch_layers.append(nn.Tanh())\n",
    "        for _ in range(depth - 1):\n",
    "            branch_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            branch_layers.append(nn.Tanh())\n",
    "        branch_layers.append(nn.Linear(hidden_dim, p * out_dim))\n",
    "        self.branch = nn.Sequential(*branch_layers)\n",
    "        \n",
    "        # Trunk network (processes coordinates)\n",
    "        trunk_layers = []\n",
    "        trunk_layers.append(nn.Linear(trunk_input_dim, hidden_dim))\n",
    "        trunk_layers.append(nn.Tanh())\n",
    "        for _ in range(depth - 1):\n",
    "            trunk_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            trunk_layers.append(nn.Tanh())\n",
    "        trunk_layers.append(nn.Linear(hidden_dim, p * out_dim))\n",
    "        self.trunk = nn.Sequential(*trunk_layers)\n",
    "        \n",
    "        # Bias\n",
    "        self.bias = nn.Parameter(torch.zeros(out_dim))\n",
    "    \n",
    "    def forward(self, u_sensors, coords):\n",
    "        \"\"\"\n",
    "        u_sensors: (B, n_sensors * channels) - values at sensor locations\n",
    "        coords: (B, N, 3) - query coordinates (x, y, t)\n",
    "        Returns: (B, N, out_dim) - predicted fields\n",
    "        \"\"\"\n",
    "        B, N, _ = coords.shape\n",
    "        \n",
    "        # Branch network\n",
    "        branch_out = self.branch(u_sensors)  # (B, p * out_dim)\n",
    "        branch_out = branch_out.view(B, self.out_dim, self.p)  # (B, out_dim, p)\n",
    "        \n",
    "        # Trunk network\n",
    "        coords_flat = coords.reshape(B * N, -1)\n",
    "        trunk_out = self.trunk(coords_flat)  # (B*N, p * out_dim)\n",
    "        trunk_out = trunk_out.view(B, N, self.out_dim, self.p)  # (B, N, out_dim, p)\n",
    "        \n",
    "        # Inner product\n",
    "        out = torch.einsum('bop,bnop->bno', branch_out, trunk_out)\n",
    "        out = out + self.bias.view(1, 1, -1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Data Loader\n",
    "# =============================================================================\n",
    "\n",
    "class CylinderWakeData:\n",
    "    def __init__(self, mat_path, n_sensors=100, seed=0):\n",
    "        data = scipy.io.loadmat(mat_path)\n",
    "        self.U_star = data[\"U_star\"]\n",
    "        self.p_star = data[\"p_star\"]\n",
    "        self.X_star = data[\"X_star\"]\n",
    "        self.t_star = data[\"t\"]\n",
    "        \n",
    "        self.N = self.X_star.shape[0]\n",
    "        self.T = self.t_star.shape[0]\n",
    "        self.n_sensors = n_sensors\n",
    "        \n",
    "        # Flatten\n",
    "        XX = np.tile(self.X_star[:, 0:1], (1, self.T))\n",
    "        YY = np.tile(self.X_star[:, 1:2], (1, self.T))\n",
    "        TT = np.tile(self.t_star, (1, self.N)).T\n",
    "        \n",
    "        self.x = XX.flatten()[:, None]\n",
    "        self.y = YY.flatten()[:, None]\n",
    "        self.t = TT.flatten()[:, None]\n",
    "        self.u = self.U_star[:, 0, :].flatten()[:, None]\n",
    "        self.v = self.U_star[:, 1, :].flatten()[:, None]\n",
    "        self.p = self.p_star.flatten()[:, None]\n",
    "        \n",
    "        self.NT = self.x.shape[0]\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        \n",
    "        # Fixed sensor locations (randomly selected spatial points)\n",
    "        self.sensor_idx = self.rng.choice(self.N, n_sensors, replace=False)\n",
    "    \n",
    "    def get_snapshot(self, t_idx):\n",
    "        \"\"\"Get full snapshot for evaluation\"\"\"\n",
    "        # Sensor values\n",
    "        u_sensor = self.U_star[self.sensor_idx, 0, t_idx]\n",
    "        v_sensor = self.U_star[self.sensor_idx, 1, t_idx]\n",
    "        p_sensor = self.p_star[self.sensor_idx, t_idx]\n",
    "        sensors = np.concatenate([u_sensor, v_sensor, p_sensor])\n",
    "        \n",
    "        # All spatial points at this time\n",
    "        x = self.X_star[:, 0:1]\n",
    "        y = self.X_star[:, 1:2]\n",
    "        t = np.full_like(x, self.t_star[t_idx, 0])\n",
    "        coords = np.concatenate([x, y, t], axis=1)\n",
    "        \n",
    "        u = self.U_star[:, 0, t_idx:t_idx+1]\n",
    "        v = self.U_star[:, 1, t_idx:t_idx+1]\n",
    "        p = self.p_star[:, t_idx:t_idx+1]\n",
    "        vals = np.concatenate([u, v, p], axis=1)\n",
    "        \n",
    "        return sensors, coords, vals\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Metrics Computation\n",
    "# =============================================================================\n",
    "\n",
    "def compute_psnr(pred, true):\n",
    "    \"\"\"\n",
    "    Compute PSNR between prediction and ground truth\n",
    "    \n",
    "    Args:\n",
    "        pred: predicted values (numpy array)\n",
    "        true: ground truth values (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        psnr: PSNR in dB\n",
    "    \"\"\"\n",
    "    pred = np.asarray(pred).flatten()\n",
    "    true = np.asarray(true).flatten()\n",
    "    \n",
    "    mse = np.mean((pred - true) ** 2)\n",
    "    if mse < 1e-12:\n",
    "        return np.inf\n",
    "    \n",
    "    # Use data range (max - min)\n",
    "    data_range = np.max(true) - np.min(true)\n",
    "    \n",
    "    return 20 * np.log10(data_range / np.sqrt(mse))\n",
    "\n",
    "\n",
    "def compute_comprehensive_metrics(model, data, device, t_index):\n",
    "    \"\"\"\n",
    "    Compute comprehensive metrics including PSNR, Rel-L2, MSE\n",
    "    \n",
    "    Args:\n",
    "        model: Trained DeepONet model\n",
    "        data: CylinderWakeData instance\n",
    "        device: torch device\n",
    "        t_index: time snapshot index\n",
    "    \n",
    "    Returns:\n",
    "        dict with all metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get test snapshot\n",
    "    test_sensors, test_coords, test_vals = data.get_snapshot(t_index)\n",
    "    test_sensors_torch = torch.tensor(test_sensors, dtype=torch.float32, \n",
    "                                     device=device).unsqueeze(0)\n",
    "    test_coords_torch = torch.tensor(test_coords, dtype=torch.float32, \n",
    "                                    device=device).unsqueeze(0)\n",
    "    \n",
    "    # Prediction\n",
    "    with torch.no_grad():\n",
    "        uvp_pred_torch = model(test_sensors_torch, test_coords_torch).squeeze(0)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    uvp_pred = uvp_pred_torch.cpu().numpy()\n",
    "    uvp_true = test_vals\n",
    "    \n",
    "    # Extract individual components\n",
    "    u_true = uvp_true[:, 0].flatten()\n",
    "    v_true = uvp_true[:, 1].flatten()\n",
    "    p_true = uvp_true[:, 2].flatten()\n",
    "    \n",
    "    u_pred = uvp_pred[:, 0].flatten()\n",
    "    v_pred = uvp_pred[:, 1].flatten()\n",
    "    p_pred = uvp_pred[:, 2].flatten()\n",
    "    \n",
    "    # MSE\n",
    "    mse_u = np.mean((u_pred - u_true) ** 2)\n",
    "    mse_v = np.mean((v_pred - v_true) ** 2)\n",
    "    mse_p = np.mean((p_pred - p_true) ** 2)\n",
    "    mse_total = (mse_u + mse_v + mse_p) / 3.0\n",
    "    \n",
    "    # Relative L2 Error\n",
    "    rel_l2_u = np.linalg.norm(u_pred - u_true, 2) / np.linalg.norm(u_true, 2)\n",
    "    rel_l2_v = np.linalg.norm(v_pred - v_true, 2) / np.linalg.norm(v_true, 2)\n",
    "    rel_l2_p = np.linalg.norm(p_pred - p_true, 2) / np.linalg.norm(p_true, 2)\n",
    "    rel_l2_avg = (rel_l2_u + rel_l2_v + rel_l2_p) / 3.0\n",
    "    \n",
    "    # PSNR\n",
    "    psnr_u = compute_psnr(u_pred, u_true)\n",
    "    psnr_v = compute_psnr(v_pred, v_true)\n",
    "    psnr_p = compute_psnr(p_pred, p_true)\n",
    "    psnr_avg = (psnr_u + psnr_v + psnr_p) / 3.0\n",
    "    \n",
    "    return {\n",
    "        'mse_u': mse_u,\n",
    "        'mse_v': mse_v,\n",
    "        'mse_p': mse_p,\n",
    "        'mse_total': mse_total,\n",
    "        'rel_l2_u': rel_l2_u,\n",
    "        'rel_l2_v': rel_l2_v,\n",
    "        'rel_l2_p': rel_l2_p,\n",
    "        'rel_l2_avg': rel_l2_avg,\n",
    "        'psnr_u': psnr_u,\n",
    "        'psnr_v': psnr_v,\n",
    "        'psnr_p': psnr_p,\n",
    "        'psnr_avg': psnr_avg,\n",
    "        'u_pred': u_pred,\n",
    "        'v_pred': v_pred,\n",
    "        'p_pred': p_pred,\n",
    "        'u_true': u_true,\n",
    "        'v_true': v_true,\n",
    "        'p_true': p_true,\n",
    "        'x': test_coords[:, 0],\n",
    "        'y': test_coords[:, 1],\n",
    "        't': data.t_star[t_index, 0],\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Model Loading\n",
    "# =============================================================================\n",
    "\n",
    "def load_deeponet_model(checkpoint_path, device, n_sensors=100, \n",
    "                        hidden_dim=128, depth=4, p=100):\n",
    "    \"\"\"\n",
    "    Load trained DeepONet model from checkpoint\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to checkpoint file\n",
    "        device: torch device\n",
    "        n_sensors: Number of sensor points (default: 100)\n",
    "        hidden_dim: Hidden layer dimension (default: 128)\n",
    "        depth: Network depth (default: 4)\n",
    "        p: Inner product dimension (default: 100)\n",
    "    \n",
    "    Returns:\n",
    "        model: Loaded DeepONet model\n",
    "        checkpoint: Checkpoint dictionary\n",
    "    \"\"\"\n",
    "    print(f\"\\nLoading DeepONet model from: {checkpoint_path}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Create model\n",
    "    branch_input_dim = n_sensors * 3  # 3 channels: u, v, p\n",
    "    model = DeepONet(\n",
    "        branch_input_dim=branch_input_dim,\n",
    "        trunk_input_dim=3,\n",
    "        hidden_dim=hidden_dim,\n",
    "        depth=depth,\n",
    "        p=p,\n",
    "        out_dim=3\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"  Training step: {checkpoint.get('step', 'N/A')}\")\n",
    "    print(f\"  Test MSE: {checkpoint.get('test_mse', 'N/A'):.6e}\")\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Visualization\n",
    "# =============================================================================\n",
    "\n",
    "def plot_evaluation_results(metrics, save_dir='./deeponet_evaluation'):\n",
    "    \"\"\"Create comprehensive visualization of evaluation results\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    x = metrics['x']\n",
    "    y = metrics['y']\n",
    "    \n",
    "    # Detect grid structure\n",
    "    xu = np.unique(np.round(x, 10))\n",
    "    yu = np.unique(np.round(y, 10))\n",
    "    nx, ny = len(xu), len(yu)\n",
    "    \n",
    "    is_grid = (len(x) == nx * ny)\n",
    "    \n",
    "    if is_grid:\n",
    "        x_to_i = {val: i for i, val in enumerate(xu)}\n",
    "        y_to_j = {val: j for j, val in enumerate(yu)}\n",
    "        \n",
    "        def to_grid(values):\n",
    "            grid = np.full((ny, nx), np.nan)\n",
    "            for xi, yi, val in zip(np.round(x, 10), np.round(y, 10), values):\n",
    "                grid[y_to_j[yi], x_to_i[xi]] = val\n",
    "            return grid\n",
    "        \n",
    "        extent = [xu.min(), xu.max(), yu.min(), yu.max()]\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    gs = GridSpec(4, 4, figure=fig, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    variables = ['u', 'v', 'p']\n",
    "    var_names = ['u-velocity', 'v-velocity', 'pressure']\n",
    "    \n",
    "    for i, (var, var_name) in enumerate(zip(variables, var_names)):\n",
    "        true_val = metrics[f'{var}_true']\n",
    "        pred_val = metrics[f'{var}_pred']\n",
    "        err_val = np.abs(pred_val - true_val)\n",
    "        rel_err_val = err_val / (np.abs(true_val) + 1e-10)\n",
    "        \n",
    "        # True field\n",
    "        ax = fig.add_subplot(gs[i, 0])\n",
    "        if is_grid:\n",
    "            grid = to_grid(true_val)\n",
    "            im = ax.imshow(grid, origin='lower', aspect='auto', extent=extent,\n",
    "                          cmap='RdBu_r', interpolation='bilinear')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "        else:\n",
    "            im = ax.scatter(x, y, c=true_val, s=2, cmap='RdBu_r')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "            ax.set_aspect('equal')\n",
    "        ax.set_title(f'{var_name} (Ground Truth)')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Predicted field\n",
    "        ax = fig.add_subplot(gs[i, 1])\n",
    "        if is_grid:\n",
    "            grid = to_grid(pred_val)\n",
    "            im = ax.imshow(grid, origin='lower', aspect='auto', extent=extent,\n",
    "                          cmap='RdBu_r', interpolation='bilinear')\n",
    "            ax.set_xlabel('x')\n",
    "        else:\n",
    "            im = ax.scatter(x, y, c=pred_val, s=2, cmap='RdBu_r')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_aspect('equal')\n",
    "        ax.set_title(f'{var_name} (Prediction)')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Absolute error\n",
    "        ax = fig.add_subplot(gs[i, 2])\n",
    "        if is_grid:\n",
    "            grid = to_grid(err_val)\n",
    "            im = ax.imshow(grid, origin='lower', aspect='auto', extent=extent,\n",
    "                          cmap='hot', interpolation='bilinear')\n",
    "            ax.set_xlabel('x')\n",
    "        else:\n",
    "            im = ax.scatter(x, y, c=err_val, s=2, cmap='hot')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_aspect('equal')\n",
    "        ax.set_title(f'{var_name} (Abs Error)')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Relative error\n",
    "        ax = fig.add_subplot(gs[i, 3])\n",
    "        if is_grid:\n",
    "            grid = to_grid(rel_err_val)\n",
    "            im = ax.imshow(grid, origin='lower', aspect='auto', extent=extent,\n",
    "                          cmap='hot', interpolation='bilinear', vmax=0.5)\n",
    "            ax.set_xlabel('x')\n",
    "        else:\n",
    "            im = ax.scatter(x, y, c=np.clip(rel_err_val, 0, 0.5), s=2, cmap='hot')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_aspect('equal')\n",
    "        ax.set_title(f'{var_name} (Rel Error)')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Add metrics text\n",
    "    ax = fig.add_subplot(gs[3, :])\n",
    "    ax.axis('off')\n",
    "    \n",
    "    metrics_text = f\"\"\"\n",
    "DeepONet EVALUATION METRICS (t={metrics['t']:.3f})\n",
    "{'='*80}\n",
    "\n",
    "Mean Squared Error (MSE):\n",
    "  u-velocity: {metrics['mse_u']:.6e}\n",
    "  v-velocity: {metrics['mse_v']:.6e}\n",
    "  pressure:   {metrics['mse_p']:.6e}\n",
    "  Average:    {metrics['mse_total']:.6e}\n",
    "\n",
    "Relative L2 Error:\n",
    "  u-velocity: {metrics['rel_l2_u']:.6f}\n",
    "  v-velocity: {metrics['rel_l2_v']:.6f}\n",
    "  pressure:   {metrics['rel_l2_p']:.6f}\n",
    "  Average:    {metrics['rel_l2_avg']:.6f}\n",
    "\n",
    "Peak Signal-to-Noise Ratio (PSNR):\n",
    "  u-velocity: {metrics['psnr_u']:.2f} dB\n",
    "  v-velocity: {metrics['psnr_v']:.2f} dB\n",
    "  pressure:   {metrics['psnr_p']:.2f} dB\n",
    "  Average:    {metrics['psnr_avg']:.2f} dB\n",
    "    \"\"\"\n",
    "    \n",
    "    ax.text(0.1, 0.5, metrics_text, transform=ax.transAxes,\n",
    "           fontsize=10, verticalalignment='center', fontfamily='monospace',\n",
    "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    fig.suptitle('DeepONet Model Evaluation Results', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    save_path = os.path.join(save_dir, 'evaluation_results.png')\n",
    "    plt.savefig(save_path, dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"\\nSaved evaluation plot to: {save_path}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main Evaluation Function\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_deeponet(checkpoint_path, data_path, t_index=100, n_sensors=100,\n",
    "                      hidden_dim=128, depth=4, p=100, device='cuda'):\n",
    "    \"\"\"\n",
    "    Complete evaluation pipeline for DeepONet model\n",
    "    \"\"\"\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    model, checkpoint = load_deeponet_model(checkpoint_path, device, \n",
    "                                           n_sensors, hidden_dim, depth, p)\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"\\nLoading data from: {data_path}\")\n",
    "    data = CylinderWakeData(data_path, n_sensors=n_sensors, seed=0)\n",
    "    print(f\"  Spatial points: {data.N}\")\n",
    "    print(f\"  Time steps: {data.T}\")\n",
    "    print(f\"  Sensors: {n_sensors}\")\n",
    "    \n",
    "    # Compute metrics\n",
    "    print(f\"\\nComputing comprehensive metrics at t_index={t_index}...\")\n",
    "    metrics = compute_comprehensive_metrics(model, data, device, t_index)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"DeepONet EVALUATION METRICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Time: t={metrics['t']:.3f}\")\n",
    "    print(f\"\\nMean Squared Error (MSE):\")\n",
    "    print(f\"  u-velocity: {metrics['mse_u']:.6e}\")\n",
    "    print(f\"  v-velocity: {metrics['mse_v']:.6e}\")\n",
    "    print(f\"  pressure:   {metrics['mse_p']:.6e}\")\n",
    "    print(f\"  Average:    {metrics['mse_total']:.6e}\")\n",
    "    \n",
    "    print(f\"\\nRelative L2 Error:\")\n",
    "    print(f\"  u-velocity: {metrics['rel_l2_u']:.6f}\")\n",
    "    print(f\"  v-velocity: {metrics['rel_l2_v']:.6f}\")\n",
    "    print(f\"  pressure:   {metrics['rel_l2_p']:.6f}\")\n",
    "    print(f\"  Average:    {metrics['rel_l2_avg']:.6f}\")\n",
    "    \n",
    "    print(f\"\\nPeak Signal-to-Noise Ratio (PSNR):\")\n",
    "    print(f\"  u-velocity: {metrics['psnr_u']:.2f} dB\")\n",
    "    print(f\"  v-velocity: {metrics['psnr_v']:.2f} dB\")\n",
    "    print(f\"  pressure:   {metrics['psnr_p']:.2f} dB\")\n",
    "    print(f\"  Average:    {metrics['psnr_avg']:.2f} dB\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    save_dir = os.path.join(os.path.dirname(checkpoint_path), 'deeponet_evaluation')\n",
    "    plot_evaluation_results(metrics, save_dir)\n",
    "    \n",
    "    # Save metrics to checkpoint\n",
    "    save_metrics = input(\"Save metrics to checkpoint? (y/n): \")\n",
    "    if save_metrics.lower() == 'y':\n",
    "        checkpoint['evaluation_metrics'] = metrics\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Metrics saved to: {checkpoint_path}\")\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Evaluate trained DeepONet model')\n",
    "    # parser.add_argument('--checkpoint', type=str, required=True,default='pat_physics_best.pt',\n",
    "    #                    help='Path to checkpoint file')\n",
    "    parser.add_argument('--data_path', type=str, default='./cylinder_nektar_wake.mat',\n",
    "                       help='Path to data file')\n",
    "    parser.add_argument('--t_index', type=int, default=100,\n",
    "                       help='Time index for evaluation')\n",
    "    parser.add_argument('--n_sensors', type=int, default=2500,\n",
    "                       help='Number of sensor points')\n",
    "    parser.add_argument('--hidden_dim', type=int, default=128,\n",
    "                       help='Hidden layer dimension')\n",
    "    parser.add_argument('--depth', type=int, default=4,\n",
    "                       help='Network depth')\n",
    "    parser.add_argument('--p', type=int, default=100,\n",
    "                       help='Inner product dimension')\n",
    "    parser.add_argument('--device', type=str, default='cpu',\n",
    "                       help='Device (cuda/cpu)')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    checkpoint = 'pat_physics_best.pt'\n",
    "    evaluate_deeponet(\n",
    "        checkpoint_path=checkpoint,\n",
    "        data_path=args.data_path,\n",
    "        t_index=args.t_index,\n",
    "        n_sensors=args.n_sensors,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        depth=args.depth,\n",
    "        p=args.p,\n",
    "        device=args.device\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
